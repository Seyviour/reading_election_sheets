{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58602"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "election_data = pd.read_csv(\"data/filtered.csv\")\n",
    "len(election_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57927"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out invalid sheets\n",
    "election_data = election_data[election_data[\"Result_Sheet_Invalid\"]==False]\n",
    "len(election_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56694"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out unclear sheets\n",
    "election_data = election_data[election_data[\"Result_Sheet_Unclear\"]==False]\n",
    "election_data = election_data[election_data[\"Accredited_Voters\"]>0]\n",
    "len(election_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56694"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "election_data[\"PU-Code\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48694"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out election sheets that had been tampered with\n",
    "election_data = election_data[election_data[\"Result_Sheet_Corrected\"]==False]\n",
    "len(election_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    Reason: The parties had 'strongholds' in different states. We don't want the models overfitting to that in any way.\\n\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Sampling Strategy:\n",
    "        For each party:\n",
    "            For each state:\n",
    "                Sample 60% of results where the party won\n",
    "                    Ensuring stratificatin across 10 bins \n",
    "            \n",
    "        For any state where the number of sampled votes < 999:\n",
    "            add more samples to make it up to 999 \n",
    "\"\"\"\n",
    "\"\"\"\n",
    "    Reason: The parties had 'strongholds' in different states. We don't want the models overfitting to that in any way.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function for each party\n",
    "def apply_sampling_for_all_parties(df, state_column):\n",
    "    parties = ['APC', 'LP', 'PDP', 'NNPP']\n",
    "    all_samples = []\n",
    "\n",
    "    for party in parties:\n",
    "        party_samples = stratified_sampling_with_wins(\n",
    "            df=df,\n",
    "            party_column=party,\n",
    "            state_column=state_column,\n",
    "            n_bins=10,\n",
    "            bin_samples=250,\n",
    "            win_samples=85,\n",
    "            random_state=42\n",
    "        )\n",
    "        all_samples.append(party_samples)\n",
    "\n",
    "    return pd.concat(all_samples)\n",
    "\n",
    "# Example usage\n",
    "# df = pd.read_csv('election_results.csv')\n",
    "# sampled_df = apply_sampling_for_all_parties(df, state_column='State')\n",
    "# sampled_df.to_csv('sampled_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_row_count = election_data.drop_duplicates().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58602\n",
      "1199\n",
      "1212\n",
      "1836\n",
      "1882\n",
      "2201\n",
      "2273\n",
      "2570\n",
      "2711\n",
      "2792\n",
      "3659\n",
      "3981\n",
      "5190\n",
      "5274\n",
      "5569\n",
      "6227\n",
      "7473\n",
      "8135\n",
      "8145\n",
      "8197\n",
      "8210\n",
      "8811\n",
      "9005\n",
      "9772\n",
      "10607\n",
      "10730\n",
      "11679\n",
      "11797\n",
      "13716\n",
      "14259\n",
      "14413\n",
      "14491\n",
      "14953\n",
      "14996\n",
      "YOBE LP empty\n",
      "15680\n",
      "15741\n",
      "15760\n",
      "16257\n",
      "16687\n",
      "16747\n",
      "16844\n",
      "16856\n",
      "18210\n",
      "18300\n",
      "19528\n",
      "19553\n",
      "20394\n",
      "20939\n",
      "ZAMFARA LP empty\n",
      "22816\n",
      "23175\n",
      "23187\n",
      "SOKOTO LP empty\n",
      "23667\n",
      "23698\n",
      "23833\n",
      "24677\n",
      "24945\n",
      "25081\n",
      "25266\n",
      "25558\n",
      "25978\n",
      "26123\n",
      "26135\n",
      "26433\n",
      "27149\n",
      "27365\n",
      "27376\n",
      "28064\n",
      "28180\n",
      "28462\n",
      "28713\n",
      "29299\n",
      "29395\n",
      "29409\n",
      "29592\n",
      "29983\n",
      "30159\n",
      "30282\n",
      "30291\n",
      "30307\n",
      "30489\n",
      "30499\n",
      "30518\n",
      "31104\n",
      "31210\n",
      "31249\n",
      "31413\n",
      "31456\n",
      "31466\n",
      "31518\n",
      "31678\n",
      "32034\n",
      "33374\n",
      "33435\n",
      "33702\n",
      "Sampling completed. Files saved as 'train_data.csv', 'val_data.csv', and 'test_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"data/filtered.csv\")\n",
    "\n",
    "# Add a 'Winner' column to identify the party with the highest votes\n",
    "def get_winner(row):\n",
    "    parties = [\"APC\", \"LP\", \"PDP\"]#, \"NNPP\"] #NNPP  # Include other parties as necessary\n",
    "    winner_party = row[parties].idxmax() if row[parties].max() > 0 else None\n",
    "    winner_votes = row[parties].max() if row[parties].max() > 0 else None\n",
    "    return pd.Series([winner_party, winner_votes])\n",
    "\n",
    "df[[\"Winner\", \"Winner_Votes\"]] = df.apply(get_winner, axis=1)\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "# Remove rows where no party won\n",
    "df = df.dropna(subset=[\"Winner\"])\n",
    "# Create empty DataFrames to hold the splits\n",
    "train_data = pd.DataFrame()\n",
    "val_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "bins = [0, 10, 50, 100, 150, 200, 250, 300, 350, 400, 500, 600]\n",
    "\n",
    "# Perform the sampling for each party and state\n",
    "acc_len = 0\n",
    "train = 0 \n",
    "for party in [\"APC\", \"LP\", \"PDP\"]: #\"NNPP\"]:  # Add other parties as necessary\n",
    "    for state in df[\"State\"].unique():\n",
    "        # Filter data for the current state and party\n",
    "        state_party_data:pd.DataFrame = df[(df[\"Winner\"] == party) & (df[\"State\"] == state)]\n",
    "        \n",
    "        if state_party_data.empty:\n",
    "            print(state, party, \"empty\")\n",
    "            continue  # Skip if there are no results for the current party and state\n",
    "        num_bins = min(6, len(state_party_data))  # Ensure at least 2 bins\n",
    "        vote_bins = pd.qcut(\n",
    "            state_party_data[\"Winner_Votes\"], q=num_bins, duplicates=\"drop\"\n",
    "        )\n",
    "\n",
    "        train_df = val_df = test_df = None\n",
    "# Explicitly assign bins to the column\n",
    "        state_party_data = state_party_data.assign(Vote_Bin=vote_bins)\n",
    "        acc_len += len(state_party_data)\n",
    "\n",
    "        # print(len(state_party_data))\n",
    "        try: \n",
    "            train_df, temp_df = train_test_split(\n",
    "                state_party_data,\n",
    "                test_size=0.4,\n",
    "                stratify=state_party_data[\"Vote_Bin\"],\n",
    "                random_state=42\n",
    "            )\n",
    "            # print(f\"TrainDF: {len(train_df)}, tempDF: {len(temp_df)}\")\n",
    "        except:\n",
    "            temp_df = state_party_data\n",
    "\n",
    "        # Stratified split of temp into validation (20%) and testing (20%)\n",
    "        try:\n",
    "            val_df, test_df = train_test_split(\n",
    "                temp_df,\n",
    "                test_size=0.5,\n",
    "                stratify=temp_df[\"Vote_Bin\"],\n",
    "                random_state=42\n",
    "            )\n",
    "        except:\n",
    "            test_df = temp_df\n",
    "        \n",
    "        # Append the splits to the main DataFrames\n",
    "        if (train_df is not None):\n",
    "            train += len(train_df)\n",
    "            train_data = pd.concat([train_data, train_df])\n",
    "        if (val_df is not None):\n",
    "            val_data = pd.concat([val_data, val_df])\n",
    "        if (test_df is not None):\n",
    "            test_data = pd.concat([test_data, test_df])\n",
    "\n",
    "# Save each subset to a separate CSV file\n",
    "train_data.to_csv(\"data_splits/train_data.csv\", index=False)\n",
    "val_data.to_csv(\"data_splits/val_data.csv\", index=False)\n",
    "test_data.to_csv(\"data_splits/test_data.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Sampling completed. Files saved as 'data_splits/train_data.csv', 'data_splits/val_data.csv', and 'data_splits/test_data.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33702"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11442"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11203"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
